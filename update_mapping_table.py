#!/usr/bin/env python3
"""
ç»¼åˆæ˜ å°„è¡¨æ›´æ–°å·¥å…·
æ¯å¤©å®šæ—¶æ›´æ–°å¸ç§æ¿å—å’Œå¸‚åœºæ•°æ®çš„CSVæ–‡ä»¶
æ”¯æŒå¢é‡æ›´æ–°å’Œå®Œæ•´é‡å»º
"""

import csv
import sys
import os
import json
import argparse
from datetime import datetime
from typing import List, Dict, Optional
import logging

# æ·»åŠ utilsç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from data.sector_data import SectorFetcher

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mapping_update.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MappingTableUpdater:
    def __init__(self, csv_file: str = 'coin_mapping_table.csv', server_mode: bool = False):
        self.csv_file = csv_file
        self.server_mode = server_mode  # æœåŠ¡å™¨æ¨¡å¼ä½¿ç”¨æ›´ä¿å®ˆçš„APIè®¾ç½®
        self.fetcher = None
        self.existing_data = {}
        
    def initialize(self):
        """åˆå§‹åŒ–SectorFetcherå’ŒåŠ è½½ç°æœ‰æ•°æ®"""
        logger.info("æ­£åœ¨åˆå§‹åŒ–SectorFetcher...")
        try:
            # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„ç¼“å­˜æ–‡ä»¶
            cache_file = 'coingecko_cache_server.pkl' if self.server_mode else 'coingecko_cache.pkl'
            self.fetcher = SectorFetcher(cache_file=cache_file)
            logger.info("SectorFetcheråˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ SectorFetcheråˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # åŠ è½½ç°æœ‰æ•°æ®
        self._load_existing_data()
    
    def _load_existing_data(self):
        """åŠ è½½ç°æœ‰CSVæ–‡ä»¶ä¸­çš„æ•°æ®"""
        if not os.path.exists(self.csv_file):
            logger.info(f"CSVæ–‡ä»¶ {self.csv_file} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return
        
        try:
            with open(self.csv_file, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    ticker = row['ticker']
                    self.existing_data[ticker] = row
            logger.info(f"åŠ è½½äº† {len(self.existing_data)} æ¡ç°æœ‰æ•°æ®")
        except Exception as e:
            logger.warning(f"åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")
    
    def _get_csv_fieldnames(self) -> List[str]:
        """è·å–CSVæ–‡ä»¶çš„å­—æ®µå"""
        return [
            'ticker', 'base_symbol', 'name', 'coingecko_id',
            'market_cap_rank', 'market_cap', 'fdv', 'volume_24h',
            'price_change_24h', 'categories', 'last_updated'
        ]
    
    def _fetch_coin_data(self, ticker: str) -> Optional[Dict]:
        """è·å–å•ä¸ªå¸ç§çš„æ•°æ®"""
        try:
            logger.info(f"æ­£åœ¨è·å– {ticker} çš„æ•°æ®...")
            info = self.fetcher.get_coin_info(ticker)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if 'error' in info:
                logger.warning(f"è·å– {ticker} æ•°æ®å¤±è´¥: {info['error']}")
                return None
            
            # å°†categoriesåˆ—è¡¨è½¬æ¢ä¸ºåˆ†å·åˆ†éš”çš„å­—ç¬¦ä¸²
            categories_str = ';'.join(info['categories']) if info['categories'] else ''
            
            return {
                'ticker': ticker,
                'base_symbol': info['base_symbol'],
                'name': info['name'],
                'coingecko_id': info['coin_id'],
                'market_cap_rank': info['market_cap_rank'],
                'market_cap': info['market_cap'],
                'fdv': info['fully_diluted_valuation'],
                'volume_24h': info['total_volume'],
                'price_change_24h': info['price_change_24h'],
                'categories': categories_str,
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
        except Exception as e:
            logger.error(f"è·å– {ticker} æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return None
    
    def update_tickers(self, tickers: List[str], force_update: bool = False) -> Dict:
        """æ›´æ–°æŒ‡å®štickersçš„æ•°æ®"""
        if not self.fetcher:
            raise Exception("è¯·å…ˆè°ƒç”¨initialize()æ–¹æ³•")
        
        results = {
            'updated': 0,
            'failed': 0,
            'skipped': 0,
            'total': len(tickers)
        }
        
        updated_data = self.existing_data.copy()
        
        for i, ticker in enumerate(tickers, 1):
            logger.info(f"[{i}/{len(tickers)}] å¤„ç† {ticker}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            if not force_update and ticker in self.existing_data:
                last_updated = self.existing_data[ticker].get('last_updated', '')
                if last_updated:
                    # å¦‚æœä»Šå¤©å·²ç»æ›´æ–°è¿‡ï¼Œè·³è¿‡
                    today = datetime.now().strftime('%Y-%m-%d')
                    if last_updated.startswith(today):
                        logger.info(f"  {ticker} ä»Šå¤©å·²æ›´æ–°ï¼Œè·³è¿‡")
                        results['skipped'] += 1
                        continue
            
            # è·å–æ–°æ•°æ®
            coin_data = self._fetch_coin_data(ticker)
            if coin_data:
                updated_data[ticker] = coin_data
                results['updated'] += 1
                logger.info(f"  {ticker} æ•°æ®å·²æ›´æ–°")
            else:
                results['failed'] += 1
                logger.warning(f"  âŒ {ticker} æ•°æ®æ›´æ–°å¤±è´¥")
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        self._save_data(updated_data)
        
        return results
    
    def _save_data(self, data: Dict):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        fieldnames = self._get_csv_fieldnames()
        
        try:
            with open(self.csv_file, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                # æŒ‰tickeræ’åºå†™å…¥
                for ticker in sorted(data.keys()):
                    writer.writerow(data[ticker])
            
            logger.info(f"æ•°æ®å·²ä¿å­˜åˆ° {self.csv_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            raise
    
    def rebuild_table(self, tickers: List[str]):
        """å®Œå…¨é‡å»ºæ˜ å°„è¡¨ï¼Œåˆ†æ‰¹å¤„ç†ä»¥é¿å…APIé™åˆ¶"""
        logger.info("å¼€å§‹å®Œå…¨é‡å»ºæ˜ å°„è¡¨...")
        logger.info("ğŸ—‘ï¸ æ¸…ç©ºç°æœ‰æ•°æ®...")
        self.existing_data = {}  # æ¸…ç©ºç°æœ‰æ•°æ®
        
        # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹3ä¸ªå¸ç§ï¼Œé—´éš”æ›´é•¿
        batch_size = 3
        total_batches = (len(tickers) + batch_size - 1) // batch_size
        
        results = {
            'updated': 0,
            'failed': 0,
            'total': len(tickers)
        }
        
        all_data = {}
        
        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i + batch_size]
            current_batch = (i // batch_size) + 1
            
            logger.info(f"ğŸ“¦ å¤„ç†ç¬¬ {current_batch}/{total_batches} æ‰¹: {batch}")
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡çš„æ¯ä¸ªticker
            for ticker in batch:
                logger.info(f"ğŸ” æ­£åœ¨å¤„ç† {ticker}...")
                
                coin_data = self._fetch_coin_data(ticker)
                if coin_data:
                    all_data[ticker] = coin_data
                    results['updated'] += 1
                    logger.info(f"  âœ… {ticker} æˆåŠŸ")
                else:
                    results['failed'] += 1
                    logger.warning(f"  âŒ {ticker} å¤±è´¥")
                
                # æ¯ä¸ªå¸ç§é—´ç­‰å¾…10ç§’
                if ticker != batch[-1]:  # ä¸æ˜¯æ‰¹æ¬¡ä¸­çš„æœ€åä¸€ä¸ª
                    logger.info(f"  â³ ç­‰å¾…10ç§’...")
                    time.sleep(10)
            
            # æ‰¹æ¬¡é—´ç­‰å¾…æ›´é•¿æ—¶é—´
            if current_batch < total_batches:
                wait_time = 90  # æ‰¹æ¬¡é—´ç­‰å¾…90ç§’
                logger.info(f"â³ æ‰¹æ¬¡é—´ç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
        
        # ä¸€æ¬¡æ€§ä¿å­˜æ‰€æœ‰æ•°æ®
        if all_data:
            logger.info(f"ğŸ’¾ ä¿å­˜ {len(all_data)} ä¸ªå¸ç§çš„æ•°æ®...")
            self._save_data(all_data)
        
        return results
    
    def get_statistics(self) -> Dict:
        """è·å–æ˜ å°„è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        if not os.path.exists(self.csv_file):
            return {'total_coins': 0, 'last_update': None}
        
        total_coins = 0
        latest_update = None
        
        try:
            with open(self.csv_file, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    total_coins += 1
                    update_time = row.get('last_updated')
                    if update_time and (not latest_update or update_time > latest_update):
                        latest_update = update_time
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        
        return {
            'total_coins': total_coins,
            'last_update': latest_update,
            'file_size': os.path.getsize(self.csv_file) if os.path.exists(self.csv_file) else 0
        }

def load_tickers_from_file(file_path: str) -> List[str]:
    """ä»æ–‡ä»¶åŠ è½½tickeråˆ—è¡¨"""
    tickers = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            if file_path.endswith('.json'):
                data = json.load(f)
                if isinstance(data, list):
                    tickers = data
                elif isinstance(data, dict) and 'tickers' in data:
                    tickers = data['tickers']
            else:
                # æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªticker
                tickers = [line.strip() for line in f if line.strip()]
    except Exception as e:
        logger.error(f"ä»æ–‡ä»¶ {file_path} åŠ è½½tickerå¤±è´¥: {e}")
    
    return tickers

def main():
    parser = argparse.ArgumentParser(
        description="å¸ç§æ˜ å°„è¡¨æ›´æ–°å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä»å‘½ä»¤è¡Œå‚æ•°æ›´æ–°
  python update_mapping_table.py BTCUSDT ETHUSDT MEUSDT
  
  # ä»æ–‡ä»¶åŠ è½½tickeråˆ—è¡¨
  python update_mapping_table.py --file tickers.txt
  python update_mapping_table.py --file tickers.json
  
  # å¼ºåˆ¶æ›´æ–°æ‰€æœ‰æ•°æ®
  python update_mapping_table.py --file tickers.txt --force
  
  # å®Œå…¨é‡å»ºè¡¨
  python update_mapping_table.py --file tickers.txt --rebuild
  
  # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
  python update_mapping_table.py --stats
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python update_mapping_table.py --output my_mapping.csv BTCUSDT ETHUSDT
        """
    )
    
    parser.add_argument(
        'tickers',
        nargs='*',
        help='è¦æ›´æ–°çš„äº¤æ˜“å¯¹åˆ—è¡¨'
    )
    
    parser.add_argument(
        '--file', '-f',
        help='ä»æ–‡ä»¶åŠ è½½tickeråˆ—è¡¨ (æ”¯æŒ.txtå’Œ.jsonæ ¼å¼)'
    )
    
    parser.add_argument(
        '--output', '-o',
        default='coin_mapping_table.csv',
        help='è¾“å‡ºCSVæ–‡ä»¶å (é»˜è®¤: coin_mapping_table.csv)'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶æ›´æ–°æ‰€æœ‰æ•°æ®ï¼Œå¿½ç•¥ç¼“å­˜'
    )
    
    parser.add_argument(
        '--rebuild',
        action='store_true',
        help='å®Œå…¨é‡å»ºæ˜ å°„è¡¨'
    )
    
    parser.add_argument(
        '--stats',
        action='store_true',
        help='æ˜¾ç¤ºæ˜ å°„è¡¨ç»Ÿè®¡ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ›´æ–°å™¨
    updater = MappingTableUpdater(args.output)
    
    # å¦‚æœåªæ˜¯æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        stats = updater.get_statistics()
        print(f"æ˜ å°„è¡¨ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ–‡ä»¶: {args.output}")
        print(f"   å¸ç§æ•°é‡: {stats['total_coins']}")
        print(f"   æœ€åæ›´æ–°: {stats['last_update'] or 'N/A'}")
        if 'file_size' in stats:
            print(f"   æ–‡ä»¶å¤§å°: {stats['file_size']} å­—èŠ‚")
        return 0
    
    # è·å–tickeråˆ—è¡¨
    tickers = []
    if args.file:
        tickers = load_tickers_from_file(args.file)
        if not tickers:
            logger.error(f"ä»æ–‡ä»¶ {args.file} æœªèƒ½åŠ è½½åˆ°ä»»ä½•ticker")
            return 1
    elif args.tickers:
        tickers = args.tickers
    else:
        logger.error("è¯·æä¾›tickeråˆ—è¡¨æˆ–ä½¿ç”¨--fileå‚æ•°")
        parser.print_help()
        return 1
    
    logger.info(f"å‡†å¤‡å¤„ç† {len(tickers)} ä¸ªticker")
    
    try:
        # åˆå§‹åŒ–
        updater.initialize()
        
        # æ‰§è¡Œæ›´æ–°
        if args.rebuild:
            results = updater.rebuild_table(tickers)
        else:
            results = updater.update_tickers(tickers, args.force)
        
        # æ˜¾ç¤ºç»“æœ
        logger.info(f"æ›´æ–°å®Œæˆ!")
        logger.info(f"   æ€»è®¡: {results['total']}")
        logger.info(f"   æ›´æ–°: {results['updated']}")
        logger.info(f"   å¤±è´¥: {results['failed']}")
        logger.info(f"   è·³è¿‡: {results['skipped']}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = updater.get_statistics()
        logger.info(f"å½“å‰æ˜ å°„è¡¨åŒ…å« {stats['total_coins']} ä¸ªå¸ç§")
        
        return 0
        
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
